{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94be4f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#import of necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from string import punctuation\n",
    "\n",
    "import re\n",
    "\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53703f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>type_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'@0_o Please feel free to read my personal pos...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Stewart Lee on immigration. What's wrong with...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'All of the above. I love being alone because ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'When you're emotional but not actually sentim...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Think I've lost my comfort level in posting at...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>'inregardstomyself Oh not at all. I was thinki...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>'So what if a person really cares about you an...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>Season 1 Akane - INFP Shogo Makishima - ENTP K...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>'*Sigh*  That comes under nature, yo.  Attract...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>'Not really what you're describing, but I do k...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3998 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  posts type_new\n",
       "0     '@0_o Please feel free to read my personal pos...        E\n",
       "1     'Stewart Lee on immigration. What's wrong with...        I\n",
       "2     'All of the above. I love being alone because ...        I\n",
       "3     'When you're emotional but not actually sentim...        I\n",
       "4     Think I've lost my comfort level in posting at...        I\n",
       "...                                                 ...      ...\n",
       "3993  'inregardstomyself Oh not at all. I was thinki...        I\n",
       "3994  'So what if a person really cares about you an...        E\n",
       "3995  Season 1 Akane - INFP Shogo Makishima - ENTP K...        I\n",
       "3996  '*Sigh*  That comes under nature, yo.  Attract...        E\n",
       "3997  'Not really what you're describing, but I do k...        E\n",
       "\n",
       "[3998 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('mbti.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c99862",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c01c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test\n",
    "y = data_new.type_new\n",
    "x=data_new.drop('type_new',axis=1)\n",
    "x_train, x_test, y_train, y_test =train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dea618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of original dataset : (3998, 2)\n",
      "shape of input - training set (3198, 1)\n",
      "shape of output - training set (3198,)\n",
      "shape of input - testing set (800, 1)\n",
      "shape of output - testing set (800,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of original dataset :\", data_new.shape)\n",
    "print(\"shape of input - training set\", x_train.shape)\n",
    "print(\"shape of output - training set\", y_train.shape)\n",
    "print(\"shape of input - testing set\", x_test.shape)\n",
    "print(\"shape of output - testing set\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd38747",
   "metadata": {},
   "source": [
    "## Style-based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d5a34a",
   "metadata": {},
   "source": [
    "# Calculate word per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc41ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preposessing_mean(text):\n",
    "    #remove URLs\n",
    "    text = re.sub(r\"https?://[^,\\s]+,?\", \"\", text)\n",
    "    #replace ||| and ...\n",
    "    text = text.replace('|||', '.')\n",
    "    text = text.replace('...', '.')\n",
    "    #sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    #len\n",
    "    sentence_word_length = [len(sent.split()) for sent in sentences]\n",
    "    #mean len\n",
    "    mean_sentence_len = np.mean(sentence_word_length)\n",
    "    return mean_sentence_len\n",
    "#print(preposessing_mean(data['posts'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c11328",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp = x_test.copy() #calculate word per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f86c2278",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp['word_sent'] = data_exp['posts'].apply(lambda x: preposessing_mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa84cd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.535002266514155\n"
     ]
    }
   ],
   "source": [
    "#count average number of words in sentences\n",
    "sum = 0\n",
    "for element in data_exp['word_sent']:\n",
    "    sum += element\n",
    "a_n_w = sum/len(data_exp['word_sent'])\n",
    "print(a_n_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75d94bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of word_sent\n",
    "number =[]\n",
    "for element in data_exp['word_sent']:\n",
    "    number.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e071a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions using word per sentence\n",
    "prediction_word_per_sent=[]\n",
    "for element in number:\n",
    "    if element > a_n_w:\n",
    "        prediction_word_per_sent.append('I')\n",
    "    else:\n",
    "        prediction_word_per_sent.append('E')\n",
    "#print(prediction_word_per_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff2f794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = []\n",
    "for element in y_test:\n",
    "    check.append(element)\n",
    "#print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5223c775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51875\n"
     ]
    }
   ],
   "source": [
    "#how well does it work (Calculate word per sentence)\n",
    "accuracy = len([check[i] for i in range(0, len(check)) if check[i] == prediction_word_per_sent[i]]) / len(check)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77c9d693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58015267, 0.4363104 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(check, prediction_word_per_sent, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf25b2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.52      0.66      0.58       402\n",
      "           I       0.52      0.37      0.44       398\n",
      "\n",
      "    accuracy                           0.52       800\n",
      "   macro avg       0.52      0.52      0.51       800\n",
      "weighted avg       0.52      0.52      0.51       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['E', 'I']\n",
    "print(classification_report(check, prediction_word_per_sent, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ddeaca",
   "metadata": {},
   "source": [
    "# F (POS+frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31125343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prosessing(text):\n",
    "    #remove URLs\n",
    "    text = re.sub(r\"https?://[^,\\s]+,?\", \"\", text)\n",
    "    #remove |||\n",
    "    text = re.sub(r\"\\.?\\|\\|\\|\", \"\", text)\n",
    "    #remove number\n",
    "    text = re.sub(r\"\\d\", \"\", text)\n",
    "    # tokenization\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    #punctuation removal\n",
    "    clean_words = [w.strip(punctuation) for w in tokens]\n",
    "    #lowercase\n",
    "    clean_words = [w.lower() for w in clean_words if w != '']\n",
    "    #lemma\n",
    "    result = [lemmatizer.lemmatize(word) for word in clean_words]\n",
    "    return result\n",
    "#print(prosessing(data['posts'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "527b7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(text):\n",
    "    tags = nltk.pos_tag(text)\n",
    "    return tags\n",
    "#print(pos(prosessing(data['posts'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b30ee567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_freq_noun(text):\n",
    "    counter = 0\n",
    "    for element in text:\n",
    "        if element[1] == 'NN' or element[1] == 'NNS' or element[1] == 'NNP' or element[1] == 'NNPS':\n",
    "            counter +=1\n",
    "    a = len(text)\n",
    "    res = counter/a\n",
    "    return res\n",
    "\n",
    "def count_freq_adj(text):\n",
    "    counter = 0\n",
    "    for element in text:\n",
    "        if element[1] == 'JJ' or element[1] == 'JJS' or element[1] == 'JJR':\n",
    "            counter +=1\n",
    "    res = counter/len(text)\n",
    "    return res\n",
    "\n",
    "def count_freq_prepos(text):\n",
    "    counter = 0\n",
    "    for element in text:\n",
    "        if element[1] == 'IN':\n",
    "            counter +=1\n",
    "    res = counter/len(text)\n",
    "    return res\n",
    "\n",
    "def count_freq_article(text):\n",
    "    counter = 0\n",
    "    for element in text:\n",
    "        if element[1] == 'DT':\n",
    "            counter +=1\n",
    "    res = counter/len(text)\n",
    "    return res\n",
    "\n",
    "def count_freq_pronoun(text):\n",
    "    counter = 0\n",
    "    for element in text:\n",
    "        if element[1] == 'PRP' or element[1] == 'PRP$':\n",
    "            counter +=1\n",
    "    res = counter/len(text)\n",
    "    return res\n",
    "\n",
    "def count_freq_verb(text):\n",
    "    counter = 0\n",
    "    for element in text:\n",
    "        if element[1] == 'VB' or element[1] == 'VBG' or element[1] == 'VBD' or element[1] == 'VBN' or element[1] == 'VBP' or element[1] == 'VBZ':\n",
    "            counter +=1\n",
    "    a = len(text)\n",
    "    res = counter/a\n",
    "    return res\n",
    "\n",
    "def count_freq_adverb(text):\n",
    "    counter = 0\n",
    "    for element in text:\n",
    "        if element[1] == 'RB' or element[1] == 'RBR' or element[1] == 'RBS':\n",
    "            counter +=1\n",
    "    a = len(text)\n",
    "    res = counter/a\n",
    "    return res\n",
    "\n",
    "def count_freq_interj(text):\n",
    "    counter = 0\n",
    "    for element in text:\n",
    "        if element[1] == 'UH':\n",
    "            counter +=1\n",
    "    a = len(text)\n",
    "    res = counter/a\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44e565a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_f(element):\n",
    "    final = count_freq_noun(element) + count_freq_adj(element) + count_freq_prepos(element) + count_freq_article(element) - count_freq_pronoun(element) - count_freq_verb(element) - count_freq_adverb(element) - count_freq_interj(element) + 100\n",
    "    r = final/2\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62e38182",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbe3821a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>pos</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>'I have an inattentive ADHD, not combined.   Y...</td>\n",
       "      <td>[i, have, an, inattentive, adhd, not, combined...</td>\n",
       "      <td>[(i, NN), (have, VBP), (an, DT), (inattentive,...</td>\n",
       "      <td>50.047769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>'Jaime91 It seems to me that you are in need o...</td>\n",
       "      <td>[jaime, it, seems, to, me, that, you, are, in,...</td>\n",
       "      <td>[(jaime, NN), (it, PRP), (seems, VBZ), (to, TO...</td>\n",
       "      <td>50.059864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>'Dirk Gently ESTP 9w8 &gt; 7w8 &gt; 3w4 sp/sx|||Ti-d...</td>\n",
       "      <td>[dirk, gently, estp, w, w, w, sp/sxti-dom, acc...</td>\n",
       "      <td>[(dirk, NN), (gently, RB), (estp, VBZ), (w, JJ...</td>\n",
       "      <td>50.164590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3580</th>\n",
       "      <td>'I believe that she just didn't want to accept...</td>\n",
       "      <td>[i, believe, that, she, just, did, n't, want, ...</td>\n",
       "      <td>[(i, NN), (believe, VBP), (that, IN), (she, PR...</td>\n",
       "      <td>50.079670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>'intensity successes...   A few days ago, I wa...</td>\n",
       "      <td>[intensity, success, a, few, day, ago, i, wa, ...</td>\n",
       "      <td>[(intensity, NN), (success, NN), (a, DT), (few...</td>\n",
       "      <td>50.083787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>'Thanks  JayDubs  Miss Bingley LittleDreamer  ...</td>\n",
       "      <td>[thanks, jaydubs, miss, bingley, littledreamer...</td>\n",
       "      <td>[(thanks, NNS), (jaydubs, VBP), (miss, JJ), (b...</td>\n",
       "      <td>50.067937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>'Like seriously how do you fall out of love wi...</td>\n",
       "      <td>[like, seriously, how, do, you, fall, out, of,...</td>\n",
       "      <td>[(like, IN), (seriously, RB), (how, WRB), (do,...</td>\n",
       "      <td>50.047440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>'http://www.youtube.com/watch?v=l1p_NHFd8jM&amp;fe...</td>\n",
       "      <td>[i, ll, write, short, story, in, the, genre, o...</td>\n",
       "      <td>[(i, NN), (ll, VBP), (write, JJ), (short, JJ),...</td>\n",
       "      <td>50.136743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>'http://4.bp.blogspot.com/-9QjARWd5a84/T3OXHJJ...</td>\n",
       "      <td>[me, too, once, i, m, done, i, m, done, we, be...</td>\n",
       "      <td>[(me, PRP), (too, RB), (once, RB), (i, JJ), (m...</td>\n",
       "      <td>50.060247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>'https://www.youtube.com/watch?v=Xg8Ckamh8Gw||...</td>\n",
       "      <td>[re-reading, this, one, it, is, so, good, am, ...</td>\n",
       "      <td>[(re-reading, NN), (this, DT), (one, CD), (it,...</td>\n",
       "      <td>50.060252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  posts  \\\n",
       "518   'I have an inattentive ADHD, not combined.   Y...   \n",
       "3072  'Jaime91 It seems to me that you are in need o...   \n",
       "1264  'Dirk Gently ESTP 9w8 > 7w8 > 3w4 sp/sx|||Ti-d...   \n",
       "3580  'I believe that she just didn't want to accept...   \n",
       "1407  'intensity successes...   A few days ago, I wa...   \n",
       "...                                                 ...   \n",
       "3281  'Thanks  JayDubs  Miss Bingley LittleDreamer  ...   \n",
       "1892  'Like seriously how do you fall out of love wi...   \n",
       "557   'http://www.youtube.com/watch?v=l1p_NHFd8jM&fe...   \n",
       "2191  'http://4.bp.blogspot.com/-9QjARWd5a84/T3OXHJJ...   \n",
       "3468  'https://www.youtube.com/watch?v=Xg8Ckamh8Gw||...   \n",
       "\n",
       "                                                 lemmas  \\\n",
       "518   [i, have, an, inattentive, adhd, not, combined...   \n",
       "3072  [jaime, it, seems, to, me, that, you, are, in,...   \n",
       "1264  [dirk, gently, estp, w, w, w, sp/sxti-dom, acc...   \n",
       "3580  [i, believe, that, she, just, did, n't, want, ...   \n",
       "1407  [intensity, success, a, few, day, ago, i, wa, ...   \n",
       "...                                                 ...   \n",
       "3281  [thanks, jaydubs, miss, bingley, littledreamer...   \n",
       "1892  [like, seriously, how, do, you, fall, out, of,...   \n",
       "557   [i, ll, write, short, story, in, the, genre, o...   \n",
       "2191  [me, too, once, i, m, done, i, m, done, we, be...   \n",
       "3468  [re-reading, this, one, it, is, so, good, am, ...   \n",
       "\n",
       "                                                    pos          f  \n",
       "518   [(i, NN), (have, VBP), (an, DT), (inattentive,...  50.047769  \n",
       "3072  [(jaime, NN), (it, PRP), (seems, VBZ), (to, TO...  50.059864  \n",
       "1264  [(dirk, NN), (gently, RB), (estp, VBZ), (w, JJ...  50.164590  \n",
       "3580  [(i, NN), (believe, VBP), (that, IN), (she, PR...  50.079670  \n",
       "1407  [(intensity, NN), (success, NN), (a, DT), (few...  50.083787  \n",
       "...                                                 ...        ...  \n",
       "3281  [(thanks, NNS), (jaydubs, VBP), (miss, JJ), (b...  50.067937  \n",
       "1892  [(like, IN), (seriously, RB), (how, WRB), (do,...  50.047440  \n",
       "557   [(i, NN), (ll, VBP), (write, JJ), (short, JJ),...  50.136743  \n",
       "2191  [(me, PRP), (too, RB), (once, RB), (i, JJ), (m...  50.060247  \n",
       "3468  [(re-reading, NN), (this, DT), (one, CD), (it,...  50.060252  \n",
       "\n",
       "[800 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1['lemmas'] = data_1['posts'].apply(lambda x: prosessing(x))\n",
    "data_1['pos'] = data_1['lemmas'].apply(lambda x: pos(x))\n",
    "data_1['f'] = data_1['pos'].apply(lambda x: cal_f(x))\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edb647d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count average number of f\n",
    "sum_f = 0\n",
    "for element in data_1['f']:\n",
    "    sum_f += element\n",
    "f1 = sum_f/len(data_1['f'])\n",
    "#print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4982809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of f mer\n",
    "f_mer =[]\n",
    "for element in data_1['f']:\n",
    "    f_mer.append(element)\n",
    "#print(f_mer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93587623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction f\n",
    "prediction_f=[]\n",
    "for element in f_mer:\n",
    "    if element > f1:\n",
    "        prediction_f.append('I')\n",
    "    else:\n",
    "        prediction_f.append('E')\n",
    "#print(prediction_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd776e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.545\n"
     ]
    }
   ],
   "source": [
    "#how well does it work (f)\n",
    "accuracy = len([check[i] for i in range(0, len(check)) if check[i] == prediction_f[i]]) / len(check)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81b73a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55825243, 0.53092784])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(check, prediction_f, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9f6af1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.55      0.57      0.56       402\n",
      "           I       0.54      0.52      0.53       398\n",
      "\n",
      "    accuracy                           0.55       800\n",
      "   macro avg       0.54      0.54      0.54       800\n",
      "weighted avg       0.54      0.55      0.54       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['E', 'I']\n",
    "print(classification_report(check, prediction_f, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b20c21",
   "metadata": {},
   "source": [
    "# Verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7372c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(text):\n",
    "    li = []\n",
    "    for element in text:\n",
    "        if element not in li:\n",
    "            li.append(element)\n",
    "    return len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edcd2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_word = x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "176c4fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_word['proc'] = data_word['posts'].apply(lambda x: prosessing(x))\n",
    "data_word['counter'] = data_word['proc'].apply(lambda x: counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa51924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = []\n",
    "for element in data_word['counter']:\n",
    "    count.append(element)\n",
    "    \n",
    "l = []\n",
    "for element in data_word['proc']:\n",
    "    l.append(len(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4684ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbosity_list = []\n",
    "for element in count:\n",
    "    index = count.index(element)\n",
    "    n = l[index]\n",
    "    d = element/n\n",
    "    verbosity_list.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd36e8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3980074493348924\n"
     ]
    }
   ],
   "source": [
    "#среднее значение для verbosity\n",
    "s = 0\n",
    "for element in verbosity_list:\n",
    "    s += element\n",
    "f = s/len(verbosity_list)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3710831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[]\n",
    "for element in verbosity_list:\n",
    "    if element > f:\n",
    "        pred.append('I')\n",
    "    else:\n",
    "        pred.append('E')\n",
    "#print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a7652a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48625\n"
     ]
    }
   ],
   "source": [
    "#how well it work\n",
    "accuracy = len([check[i] for i in range(0, len(check)) if check[i] == pred[i]]) / len(check)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba37999a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48431537690617465"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(check, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "807f5858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.49      0.54      0.52       402\n",
      "           I       0.48      0.43      0.45       398\n",
      "\n",
      "    accuracy                           0.49       800\n",
      "   macro avg       0.49      0.49      0.48       800\n",
      "weighted avg       0.49      0.49      0.48       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['E', 'I']\n",
    "print(classification_report(check, pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8fb5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb5cf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3751646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_8668/2280066469.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train['posts'] = x_train['posts'].apply(lambda x: prosessing(x))\n"
     ]
    }
   ],
   "source": [
    "x_train['posts'] = x_train['posts'].apply(lambda x: prosessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "272c9394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_8668/4025758674.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_test['posts'] = x_test['posts'].apply(lambda x: prosessing(x))\n"
     ]
    }
   ],
   "source": [
    "x_test['posts'] = x_test['posts'].apply(lambda x: prosessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "900c7d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_8668/700683518.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train[\"posts\"] = x_train[\"posts\"].apply(lambda x: ' '.join(x))\n",
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_8668/700683518.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_test[\"posts\"] = x_test[\"posts\"].apply(lambda x: ' '.join(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>a an enfp i can be messy but tend to catch mys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>this mention stuff is annoyingwhat if piss wa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>you do n't understand what i mean i do n't say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>it s mostly rough guessing and process of elim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>how do you react to them can you even begin to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>blueyeah for sure i tend to be able to pick up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3365</th>\n",
       "      <td>infp because both si-te and fi-ne are apparent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606</th>\n",
       "      <td>and long married i m a big fan of ramen follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>nfpi performance artist-this type almost alway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>i fully believe in the power of being a protec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3198 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  posts\n",
       "1839  a an enfp i can be messy but tend to catch mys...\n",
       "1655  this mention stuff is annoyingwhat if piss wa ...\n",
       "2433  you do n't understand what i mean i do n't say...\n",
       "1807  it s mostly rough guessing and process of elim...\n",
       "10    how do you react to them can you even begin to...\n",
       "...                                                 ...\n",
       "2127  blueyeah for sure i tend to be able to pick up...\n",
       "3365  infp because both si-te and fi-ne are apparent...\n",
       "3606  and long married i m a big fan of ramen follow...\n",
       "2917  nfpi performance artist-this type almost alway...\n",
       "3298  i fully believe in the power of being a protec...\n",
       "\n",
       "[3198 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[\"posts\"] = x_train[\"posts\"].apply(lambda x: ' '.join(x))\n",
    "x_test[\"posts\"] = x_test[\"posts\"].apply(lambda x: ' '.join(x))\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b174828e",
   "metadata": {},
   "source": [
    "## Bag of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f271a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "X_train = count_vectorizer.fit_transform(x_train[\"posts\"])\n",
    "Y_train = y_train\n",
    "X_test = count_vectorizer.transform(x_test[\"posts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47b8308f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, max_iter=150).fit(X_train, Y_train)\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ec813ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7675"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7ce2cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.78      0.76      0.77       402\n",
      "           I       0.76      0.78      0.77       398\n",
      "\n",
      "    accuracy                           0.77       800\n",
      "   macro avg       0.77      0.77      0.77       800\n",
      "weighted avg       0.77      0.77      0.77       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['E', 'I']\n",
    "print(classification_report(check, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914b54d6",
   "metadata": {},
   "source": [
    "## Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52e851f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "\n",
    "X_train = tfidf_vectorizer.fit_transform(x_train[\"posts\"])\n",
    "Y_train = y_train\n",
    "X_test = tfidf_vectorizer.transform(x_test[\"posts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f9677f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, max_iter=150).fit(X_train, Y_train)\n",
    "predictions1 = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70d3261c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79375"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a16ecd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.82      0.76      0.79       402\n",
      "           I       0.77      0.83      0.80       398\n",
      "\n",
      "    accuracy                           0.79       800\n",
      "   macro avg       0.80      0.79      0.79       800\n",
      "weighted avg       0.80      0.79      0.79       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['E', 'I']\n",
    "print(classification_report(check, predictions1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "71792215",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr =[]\n",
    "for element in predictions:\n",
    "    pr.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "74077fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr1 = []\n",
    "for element in predictions1:\n",
    "    pr1.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "be4c474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = pr\n",
    "pred2 = pr1\n",
    "pred3 = prediction_f\n",
    "pred4 = pred\n",
    "pred5 = prediction_word_per_sent\n",
    "for_data = []\n",
    "res = []\n",
    "cof = [0.3, 0.4, 0.1, 0.1, 0.1]\n",
    "counter = 0\n",
    "while counter < 800:\n",
    "    l = []\n",
    "    l.append(pred1[counter])\n",
    "    l.append(pred2[counter])\n",
    "    l.append(pred3[counter])\n",
    "    l.append(pred4[counter])\n",
    "    l.append(pred5[counter])\n",
    "    for_data.append(l)\n",
    "    c =0\n",
    "    r_i = 0\n",
    "    r_e = 0\n",
    "    cc = 0\n",
    "    for element in l:\n",
    "        if element == \"I\":\n",
    "            r_i += cof[cc]\n",
    "        if element == \"E\":\n",
    "            r_e += cof[cc]\n",
    "        cc +=1\n",
    "    if r_i > r_e:\n",
    "        res.append('I')\n",
    "    else:\n",
    "        res.append('E')\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "92f5a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1 = pd.DataFrame(for_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3fed3a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3  4\n",
       "0    I  I  E  E  I\n",
       "1    E  E  E  E  E\n",
       "2    E  E  I  I  I\n",
       "3    I  I  I  E  E\n",
       "4    I  I  I  E  E\n",
       "..  .. .. .. .. ..\n",
       "795  I  I  I  E  E\n",
       "796  I  I  E  E  E\n",
       "797  I  I  I  I  E\n",
       "798  E  E  E  I  E\n",
       "799  I  I  E  I  I\n",
       "\n",
       "[800 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d3b67870",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "fail = []\n",
    "for element in check:\n",
    "    if element != res[ind]:\n",
    "        fail.append(ind)\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d2321bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805\n"
     ]
    }
   ],
   "source": [
    "#how well does it work \n",
    "accuracy = len([check[i] for i in range(0, len(check)) if check[i] == res[i]]) / len(check)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ded78a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.80      0.81      0.81       402\n",
      "           I       0.81      0.80      0.80       398\n",
      "\n",
      "    accuracy                           0.81       800\n",
      "   macro avg       0.81      0.80      0.80       800\n",
      "weighted avg       0.81      0.81      0.80       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['E', 'I']\n",
    "print(classification_report(check, res, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c16b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
